{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 1\n",
    "Neste caso separasse uma parte do conjunto de Teste para Classificar o conjunto de trainamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIM_1</th>\n",
       "      <th>DIM_2</th>\n",
       "      <th>DIM_3</th>\n",
       "      <th>DIM_4</th>\n",
       "      <th>DIM_5</th>\n",
       "      <th>DIM_6</th>\n",
       "      <th>DIM_7</th>\n",
       "      <th>DIM_8</th>\n",
       "      <th>DIM_9</th>\n",
       "      <th>DIM_10</th>\n",
       "      <th>DIM_11</th>\n",
       "      <th>DIM_12</th>\n",
       "      <th>DIM_13</th>\n",
       "      <th>DIM_14</th>\n",
       "      <th>DIM_15</th>\n",
       "      <th>DIM_16</th>\n",
       "      <th>DIM_17</th>\n",
       "      <th>DIM_18</th>\n",
       "      <th>DIM_19</th>\n",
       "      <th>DIM_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481778</td>\n",
       "      <td>-2.690799</td>\n",
       "      <td>1.929163</td>\n",
       "      <td>2.194800</td>\n",
       "      <td>0.481778</td>\n",
       "      <td>-1.374999</td>\n",
       "      <td>-1.374999</td>\n",
       "      <td>-2.690799</td>\n",
       "      <td>2.194800</td>\n",
       "      <td>-2.650589</td>\n",
       "      <td>1.968976</td>\n",
       "      <td>2.987171</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>-5.592626</td>\n",
       "      <td>0.481778</td>\n",
       "      <td>-5.644713</td>\n",
       "      <td>-5.592626</td>\n",
       "      <td>-3.261920</td>\n",
       "      <td>1.293436</td>\n",
       "      <td>0.056862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.758880</td>\n",
       "      <td>0.624947</td>\n",
       "      <td>3.096758</td>\n",
       "      <td>2.366358</td>\n",
       "      <td>-0.758880</td>\n",
       "      <td>0.614977</td>\n",
       "      <td>0.614977</td>\n",
       "      <td>0.624947</td>\n",
       "      <td>2.366358</td>\n",
       "      <td>-0.041634</td>\n",
       "      <td>-1.194561</td>\n",
       "      <td>0.320281</td>\n",
       "      <td>-1.095600</td>\n",
       "      <td>1.737322</td>\n",
       "      <td>-0.758880</td>\n",
       "      <td>1.703506</td>\n",
       "      <td>1.737322</td>\n",
       "      <td>-1.503375</td>\n",
       "      <td>-2.976826</td>\n",
       "      <td>-3.347693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.547708</td>\n",
       "      <td>-0.824650</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>1.946270</td>\n",
       "      <td>1.547708</td>\n",
       "      <td>2.577463</td>\n",
       "      <td>2.577463</td>\n",
       "      <td>-0.824650</td>\n",
       "      <td>1.946270</td>\n",
       "      <td>-0.986832</td>\n",
       "      <td>-1.923297</td>\n",
       "      <td>-0.587897</td>\n",
       "      <td>-1.630104</td>\n",
       "      <td>2.047893</td>\n",
       "      <td>1.547708</td>\n",
       "      <td>-1.639816</td>\n",
       "      <td>2.047893</td>\n",
       "      <td>-5.171651</td>\n",
       "      <td>0.599213</td>\n",
       "      <td>-0.236890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.593411</td>\n",
       "      <td>1.549793</td>\n",
       "      <td>3.488298</td>\n",
       "      <td>3.629761</td>\n",
       "      <td>-1.593411</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>1.549793</td>\n",
       "      <td>3.629761</td>\n",
       "      <td>-0.543969</td>\n",
       "      <td>-2.786350</td>\n",
       "      <td>-0.314272</td>\n",
       "      <td>-0.619047</td>\n",
       "      <td>2.110562</td>\n",
       "      <td>-1.593411</td>\n",
       "      <td>2.709332</td>\n",
       "      <td>2.110562</td>\n",
       "      <td>-2.212294</td>\n",
       "      <td>-3.313402</td>\n",
       "      <td>-2.805601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.085533</td>\n",
       "      <td>-1.584111</td>\n",
       "      <td>1.057157</td>\n",
       "      <td>0.850008</td>\n",
       "      <td>3.085533</td>\n",
       "      <td>1.026912</td>\n",
       "      <td>1.026912</td>\n",
       "      <td>-1.584111</td>\n",
       "      <td>0.850008</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>1.354507</td>\n",
       "      <td>0.484823</td>\n",
       "      <td>-1.107261</td>\n",
       "      <td>0.751787</td>\n",
       "      <td>3.085533</td>\n",
       "      <td>-4.033858</td>\n",
       "      <td>0.751787</td>\n",
       "      <td>-3.470866</td>\n",
       "      <td>0.811846</td>\n",
       "      <td>-2.874889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.225221</td>\n",
       "      <td>-2.022480</td>\n",
       "      <td>2.492887</td>\n",
       "      <td>2.109219</td>\n",
       "      <td>0.225221</td>\n",
       "      <td>-0.113400</td>\n",
       "      <td>-0.113400</td>\n",
       "      <td>-2.022480</td>\n",
       "      <td>2.109219</td>\n",
       "      <td>-2.115855</td>\n",
       "      <td>0.806688</td>\n",
       "      <td>2.754259</td>\n",
       "      <td>-1.220831</td>\n",
       "      <td>-3.625507</td>\n",
       "      <td>0.225221</td>\n",
       "      <td>-4.048901</td>\n",
       "      <td>-3.625507</td>\n",
       "      <td>-4.361640</td>\n",
       "      <td>0.614697</td>\n",
       "      <td>-0.884426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.685156</td>\n",
       "      <td>-1.888123</td>\n",
       "      <td>1.868993</td>\n",
       "      <td>3.164648</td>\n",
       "      <td>1.685156</td>\n",
       "      <td>0.819944</td>\n",
       "      <td>0.819944</td>\n",
       "      <td>-1.888123</td>\n",
       "      <td>3.164648</td>\n",
       "      <td>-1.777343</td>\n",
       "      <td>-0.063630</td>\n",
       "      <td>0.918951</td>\n",
       "      <td>-0.525844</td>\n",
       "      <td>-1.127290</td>\n",
       "      <td>1.685156</td>\n",
       "      <td>-4.288397</td>\n",
       "      <td>-1.127290</td>\n",
       "      <td>-5.055856</td>\n",
       "      <td>0.485159</td>\n",
       "      <td>-1.200129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.520673</td>\n",
       "      <td>-1.462370</td>\n",
       "      <td>3.473858</td>\n",
       "      <td>2.355155</td>\n",
       "      <td>0.520673</td>\n",
       "      <td>0.524558</td>\n",
       "      <td>0.524558</td>\n",
       "      <td>-1.462370</td>\n",
       "      <td>2.355155</td>\n",
       "      <td>-0.945509</td>\n",
       "      <td>0.457348</td>\n",
       "      <td>2.104907</td>\n",
       "      <td>-2.036561</td>\n",
       "      <td>-0.670842</td>\n",
       "      <td>0.520673</td>\n",
       "      <td>-2.126162</td>\n",
       "      <td>-0.670842</td>\n",
       "      <td>-3.902823</td>\n",
       "      <td>-1.457445</td>\n",
       "      <td>-3.471213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.353294</td>\n",
       "      <td>1.534632</td>\n",
       "      <td>3.749267</td>\n",
       "      <td>2.671265</td>\n",
       "      <td>-1.353294</td>\n",
       "      <td>0.829007</td>\n",
       "      <td>0.829007</td>\n",
       "      <td>1.534632</td>\n",
       "      <td>2.671265</td>\n",
       "      <td>0.311106</td>\n",
       "      <td>-1.871476</td>\n",
       "      <td>0.243888</td>\n",
       "      <td>-1.184842</td>\n",
       "      <td>2.051934</td>\n",
       "      <td>-1.353294</td>\n",
       "      <td>2.585362</td>\n",
       "      <td>2.051934</td>\n",
       "      <td>-1.762989</td>\n",
       "      <td>-3.270411</td>\n",
       "      <td>-3.847704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.580345</td>\n",
       "      <td>0.631322</td>\n",
       "      <td>0.713587</td>\n",
       "      <td>2.303129</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>2.815299</td>\n",
       "      <td>2.815299</td>\n",
       "      <td>0.631322</td>\n",
       "      <td>2.303129</td>\n",
       "      <td>-0.772003</td>\n",
       "      <td>-3.148032</td>\n",
       "      <td>-0.912143</td>\n",
       "      <td>-1.194035</td>\n",
       "      <td>1.789704</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>-0.792237</td>\n",
       "      <td>1.789704</td>\n",
       "      <td>-5.637653</td>\n",
       "      <td>1.119476</td>\n",
       "      <td>0.322888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DIM_1     DIM_2     DIM_3     DIM_4     DIM_5     DIM_6     DIM_7  \\\n",
       "0  0.481778 -2.690799  1.929163  2.194800  0.481778 -1.374999 -1.374999   \n",
       "1 -0.758880  0.624947  3.096758  2.366358 -0.758880  0.614977  0.614977   \n",
       "2  1.547708 -0.824650  0.446411  1.946270  1.547708  2.577463  2.577463   \n",
       "3 -1.593411  1.549793  3.488298  3.629761 -1.593411  0.998859  0.998859   \n",
       "4  3.085533 -1.584111  1.057157  0.850008  3.085533  1.026912  1.026912   \n",
       "5  0.225221 -2.022480  2.492887  2.109219  0.225221 -0.113400 -0.113400   \n",
       "6  1.685156 -1.888123  1.868993  3.164648  1.685156  0.819944  0.819944   \n",
       "7  0.520673 -1.462370  3.473858  2.355155  0.520673  0.524558  0.524558   \n",
       "8 -1.353294  1.534632  3.749267  2.671265 -1.353294  0.829007  0.829007   \n",
       "9  0.580345  0.631322  0.713587  2.303129  0.580345  2.815299  2.815299   \n",
       "\n",
       "      DIM_8     DIM_9    DIM_10    DIM_11    DIM_12    DIM_13    DIM_14  \\\n",
       "0 -2.690799  2.194800 -2.650589  1.968976  2.987171  0.224900 -5.592626   \n",
       "1  0.624947  2.366358 -0.041634 -1.194561  0.320281 -1.095600  1.737322   \n",
       "2 -0.824650  1.946270 -0.986832 -1.923297 -0.587897 -1.630104  2.047893   \n",
       "3  1.549793  3.629761 -0.543969 -2.786350 -0.314272 -0.619047  2.110562   \n",
       "4 -1.584111  0.850008  0.642361  1.354507  0.484823 -1.107261  0.751787   \n",
       "5 -2.022480  2.109219 -2.115855  0.806688  2.754259 -1.220831 -3.625507   \n",
       "6 -1.888123  3.164648 -1.777343 -0.063630  0.918951 -0.525844 -1.127290   \n",
       "7 -1.462370  2.355155 -0.945509  0.457348  2.104907 -2.036561 -0.670842   \n",
       "8  1.534632  2.671265  0.311106 -1.871476  0.243888 -1.184842  2.051934   \n",
       "9  0.631322  2.303129 -0.772003 -3.148032 -0.912143 -1.194035  1.789704   \n",
       "\n",
       "     DIM_15    DIM_16    DIM_17    DIM_18    DIM_19    DIM_20  \n",
       "0  0.481778 -5.644713 -5.592626 -3.261920  1.293436  0.056862  \n",
       "1 -0.758880  1.703506  1.737322 -1.503375 -2.976826 -3.347693  \n",
       "2  1.547708 -1.639816  2.047893 -5.171651  0.599213 -0.236890  \n",
       "3 -1.593411  2.709332  2.110562 -2.212294 -3.313402 -2.805601  \n",
       "4  3.085533 -4.033858  0.751787 -3.470866  0.811846 -2.874889  \n",
       "5  0.225221 -4.048901 -3.625507 -4.361640  0.614697 -0.884426  \n",
       "6  1.685156 -4.288397 -1.127290 -5.055856  0.485159 -1.200129  \n",
       "7  0.520673 -2.126162 -0.670842 -3.902823 -1.457445 -3.471213  \n",
       "8 -1.353294  2.585362  2.051934 -1.762989 -3.270411 -3.847704  \n",
       "9  0.580345 -0.792237  1.789704 -5.637653  1.119476  0.322888  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ = pd.read_csv(\"X_train.csv\") \n",
    "X_test_ = pd.read_csv(\"X_test.csv\") \n",
    "y_test_ = pd.read_csv(\"y_test.csv\") \n",
    "X_test_.columns =['DIM_1', 'DIM_2', 'DIM_3', 'DIM_4', 'DIM_5', 'DIM_6', 'DIM_7', \n",
    "                 'DIM_8', 'DIM_9', 'DIM_10', 'DIM_11', 'DIM_12','DIM_13', 'DIM_14',\n",
    "                 'DIM_15', 'DIM_16','DIM_17', 'DIM_18', 'DIM_19', 'DIM_20',]\n",
    "y_test_.columns =['OUT']\n",
    "X_train_.columns =['DIM_1', 'DIM_2', 'DIM_3', 'DIM_4', 'DIM_5', 'DIM_6', 'DIM_7', \n",
    "                 'DIM_8', 'DIM_9', 'DIM_10', 'DIM_11', 'DIM_12','DIM_13', 'DIM_14',\n",
    "                 'DIM_15', 'DIM_16','DIM_17', 'DIM_18', 'DIM_19', 'DIM_20',]\n",
    "#test_ = pd.concat([X_test, y_test], axis=1)\n",
    "#test_.head()\n",
    "#X_test.isnull().sum()\n",
    "#X_test_ = X_test.dropna()\n",
    "#train_test_split(X_test, test_size=0.05)\n",
    "#train, test  = train_test_split(test_, test_size=0.05)\n",
    "X_test_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#X_train_ = X_train.dropna()\n",
    "#print(X_train_.isnull().sum())\n",
    "imp_mean = SimpleImputer( strategy='mean')\n",
    "imp_mean.fit(X_train_)\n",
    "\n",
    "X_train_ = imp_mean.transform(X_train_)\n",
    "#X_train_ = imp_mean.transform(X_train)\n",
    "\n",
    "imp_mean = SimpleImputer( strategy='mean', missing_values=np.NaN)\n",
    "imp_mean.fit(X_train_)\n",
    "X_train_ = imp_mean.transform(X_train_)\n",
    "#X_train_.shape\n",
    "\n",
    "#X_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X_test_, y_test_)\n",
    "\n",
    "for train_index, test_index in sss.split(X_test_, y_test_):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train__test, X_traintest = X_test_.iloc[train_index], X_test_.iloc[test_index]\n",
    "    y_train__test, y_traintest = y_test_.iloc[train_index], y_test_.iloc[test_index]\n",
    "#y_traintest.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_traintest.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "polynomial_svm_clf = Pipeline([(\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "                                (\"scaler\", StandardScaler()),\n",
    "                                (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    "                                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_svm_clf.fit(X_traintest, np.squeeze(y_traintest.T))\n",
    "y_train_pred = polynomial_svm_clf.predict(X_train_)\n",
    "y_train_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar um classificador stacking\n",
    "Usando os rotulos calculados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "base_models = [('random_forest', RandomForestClassifier(n_estimators=50)),\n",
    "               ('svm', SVC()),\n",
    "               ('knn', KNeighborsClassifier(n_neighbors=11))]\n",
    "meta_model = LogisticRegressionCV()\n",
    "stacking_model = StackingClassifier(estimators=base_models, \n",
    "                                    final_estimator=meta_model, \n",
    "                                    stack_method='predict',\n",
    "                                    #passthrough=True, \n",
    "                                    cv=5,\n",
    "                                    verbose=2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, verbose=1, n_jobs=3, error_score='raise')\n",
    "    return scores\n",
    "model_scores = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "stacking_scores = evaluate_model(stacking_model, X_train_, y_train_pred)\n",
    "model_scores['stacking'] = stacking_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('random_forest',\n",
       "                                RandomForestClassifier(n_estimators=50)),\n",
       "                               ('svm', SVC()),\n",
       "                               ('knn', KNeighborsClassifier(n_neighbors=11))],\n",
       "                   final_estimator=LogisticRegressionCV(),\n",
       "                   stack_method='predict', verbose=2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.fit(X_train_, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conferindo o teste\n",
    "y_test_predict = stacking_model.predict(X_train__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55, 24],\n",
       "       [15, 65]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train__test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
